# MR HelpMate AI
In this project, implementing all three layers effectively is crucial for building a robust search system. Exploring various strategies and conducting experiments across these layers will enhance the overall performance. Let’s delve into what each layer entails and the experimentation possibilities based on different choices.

## The Embedding Layer
In the embedding layer, the processing of the PDF document is essential. This involves cleaning and chunking the document effectively. The strategy chosen for chunking significantly influences the quality of the results retrieved later. Therefore, experimenting with different chunking strategies and comparing their performances is vital.

Another key consideration in this layer is the selection of the embedding model. Options include using the OpenAI embedding model or any model available from the SentenceTransformers library on HuggingFace. Each choice can lead to different outcomes in the embedding quality.

## The Search Layer
Moving to the search layer, the first step involves designing at least three queries to test the system. This requires a thorough understanding of the document to formulate queries that can be answered using the information contained within it.

Once the queries are established, they need to be embedded, and the ChromaDB vector database should be searched against each query. Implementing a caching mechanism is also an important aspect of this layer to enhance efficiency.

Finally, the re-ranking block must be implemented. For this, a variety of cross-encoding models available on HuggingFace can be utilized, allowing for flexibility in how results are prioritized.

## The Generation Layer
In the generation layer, the design of the final prompt is a critical component. It’s important that the prompt is comprehensive, providing clear instructions and ensuring that all relevant information is conveyed effectively. Additionally, incorporating few-shot examples can be beneficial in improving the output from the language model.

## Outputs required: 

Top 3 Results from the Search Layer: You need to share 3 screenshots against 3 self-designed queries that clearly showcase the top 3 results/chunks retrieved from the search layer. Please share 1 screenshot for each query and its output.

Final Generated Answer from the Generation Layer: Here, you are required to share 3 screenshots of the same 3 queries with the final output generated by the LLM in the generation layer. Please share one screenshot for each query and its output.
